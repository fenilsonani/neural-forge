

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Functional Module &mdash; Neural Architecture 2.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=51b770b3"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Neural Network Module" href="nn.html" />
    <link rel="prev" title="Core Module" href="core.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="../index.html" class="icon icon-home">
            Neural Architecture
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick Start Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="core.html">Core Module</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Functional Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#arithmetic-operations">Arithmetic Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.add"><code class="docutils literal notranslate"><span class="pre">add()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.sub"><code class="docutils literal notranslate"><span class="pre">sub()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.mul"><code class="docutils literal notranslate"><span class="pre">mul()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.div"><code class="docutils literal notranslate"><span class="pre">div()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.neg"><code class="docutils literal notranslate"><span class="pre">neg()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.matmul"><code class="docutils literal notranslate"><span class="pre">matmul()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#activation-functions">Activation Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.relu"><code class="docutils literal notranslate"><span class="pre">relu()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.sigmoid"><code class="docutils literal notranslate"><span class="pre">sigmoid()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.tanh"><code class="docutils literal notranslate"><span class="pre">tanh()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.softmax"><code class="docutils literal notranslate"><span class="pre">softmax()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pooling-operations">Pooling Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.mean_pool"><code class="docutils literal notranslate"><span class="pre">mean_pool()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.max_pool"><code class="docutils literal notranslate"><span class="pre">max_pool()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#loss-functions">Loss Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.cross_entropy_loss"><code class="docutils literal notranslate"><span class="pre">cross_entropy_loss()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.mse_loss"><code class="docutils literal notranslate"><span class="pre">mse_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#utility-functions">Utility Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.utils.broadcast_tensors"><code class="docutils literal notranslate"><span class="pre">broadcast_tensors()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.utils.reduce_gradient"><code class="docutils literal notranslate"><span class="pre">reduce_gradient()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.utils.get_broadcast_shape"><code class="docutils literal notranslate"><span class="pre">get_broadcast_shape()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.utils.validate_tensor_operation"><code class="docutils literal notranslate"><span class="pre">validate_tensor_operation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.utils.ensure_tensor"><code class="docutils literal notranslate"><span class="pre">ensure_tensor()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.utils.compute_output_shape"><code class="docutils literal notranslate"><span class="pre">compute_output_shape()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.utils.check_finite_gradients"><code class="docutils literal notranslate"><span class="pre">check_finite_gradients()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.utils.apply_gradient_clipping"><code class="docutils literal notranslate"><span class="pre">apply_gradient_clipping()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#neural_arch.functional.utils.memory_efficient_operation"><code class="docutils literal notranslate"><span class="pre">memory_efficient_operation()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#examples">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-operations">Basic Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#broadcasting-examples">Broadcasting Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="#activation-function-usage">Activation Function Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loss-function-examples">Loss Function Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#performance-notes">Performance Notes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">Neural Network Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">Optimization Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="config.html">Configuration Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command Line Interface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py-modindex.html">Module Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="../search.html">Search Page</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Neural Architecture</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Functional Module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/functional.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="functional-module">
<h1>Functional Module<a class="headerlink" href="#functional-module" title="Link to this heading"></a></h1>
<p>The functional module provides low-level tensor operations that form the building blocks of neural networks.</p>
<section id="arithmetic-operations">
<h2>Arithmetic Operations<a class="headerlink" href="#arithmetic-operations" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.add">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/arithmetic.html#add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.add" title="Link to this definition"></a></dt>
<dd><p>Element-wise addition with broadcasting and gradient support.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – First operand</p></li>
<li><p><strong>b</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – Second operand</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Result tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Mathematical Definition:</dt><dd><p>output = a + b
∂output/∂a = 1 (broadcasted to a.shape)
∂output/∂b = 1 (broadcasted to b.shape)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.sub">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">sub</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/arithmetic.html#sub"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.sub" title="Link to this definition"></a></dt>
<dd><p>Element-wise subtraction with broadcasting and gradient support.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – First operand (minuend)</p></li>
<li><p><strong>b</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – Second operand (subtrahend)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Result tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Mathematical Definition:</dt><dd><p>output = a - b
∂output/∂a = 1 (broadcasted to a.shape)
∂output/∂b = -1 (broadcasted to b.shape)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.mul">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">mul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/arithmetic.html#mul"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.mul" title="Link to this definition"></a></dt>
<dd><p>Element-wise multiplication with broadcasting and gradient support.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – First operand</p></li>
<li><p><strong>b</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – Second operand</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Result tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Mathematical Definition:</dt><dd><p>output = a * b
∂output/∂a = b (broadcasted to a.shape)
∂output/∂b = a (broadcasted to b.shape)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.div">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">div</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/arithmetic.html#div"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.div" title="Link to this definition"></a></dt>
<dd><p>Element-wise division with broadcasting and gradient support.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – Numerator</p></li>
<li><p><strong>b</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</span>) – Denominator</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Result tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Mathematical Definition:</dt><dd><p>output = a / b
∂output/∂a = 1/b (broadcasted to a.shape)
∂output/∂b = -a/b² (broadcasted to b.shape)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If denominator contains zeros</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.neg">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">neg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/arithmetic.html#neg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.neg" title="Link to this definition"></a></dt>
<dd><p>Element-wise negation with gradient support.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>a</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Input tensor</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Negated tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Mathematical Definition:</dt><dd><p>output = -a
∂output/∂a = -1</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.matmul">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">matmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/arithmetic.html#matmul"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.matmul" title="Link to this definition"></a></dt>
<dd><p>Matrix multiplication with gradient support.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Left matrix tensor</p></li>
<li><p><strong>b</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Right matrix tensor</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Matrix multiplication result</p>
</dd>
</dl>
<dl class="simple">
<dt>Mathematical Definition:</dt><dd><p>output = a &#64; b
∂output/∂a = grad_output &#64; b.T
∂output/∂b = a.T &#64; grad_output</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If matrix dimensions are incompatible</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="activation-functions">
<h2>Activation Functions<a class="headerlink" href="#activation-functions" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.relu">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">relu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_arch.functional.relu" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.sigmoid">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_arch.functional.sigmoid" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.tanh">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">tanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_arch.functional.tanh" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.softmax">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_arch.functional.softmax" title="Link to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="pooling-operations">
<h2>Pooling Operations<a class="headerlink" href="#pooling-operations" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.mean_pool">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">mean_pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_arch.functional.mean_pool" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.max_pool">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">max_pool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_arch.functional.max_pool" title="Link to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="loss-functions">
<h2>Loss Functions<a class="headerlink" href="#loss-functions" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.cross_entropy_loss">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">cross_entropy_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_arch.functional.cross_entropy_loss" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.mse_loss">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.</span></span><span class="sig-name descname"><span class="pre">mse_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_arch.functional.mse_loss" title="Link to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="utility-functions">
<h2>Utility Functions<a class="headerlink" href="#utility-functions" title="Link to this heading"></a></h2>
<p id="module-neural_arch.functional.utils">Utility functions for tensor operations.</p>
<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.utils.broadcast_tensors">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.utils.</span></span><span class="sig-name descname"><span class="pre">broadcast_tensors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">tensors</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/utils.html#broadcast_tensors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.utils.broadcast_tensors" title="Link to this definition"></a></dt>
<dd><p>Broadcast multiple tensors to a common shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*tensors</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Variable number of tensors to broadcast</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code></a>[<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of broadcasted numpy arrays</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If tensors cannot be broadcasted together</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.utils.reduce_gradient">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.utils.</span></span><span class="sig-name descname"><span class="pre">reduce_gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">broadcast_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/utils.html#reduce_gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.utils.reduce_gradient" title="Link to this definition"></a></dt>
<dd><p>Reduce gradient from broadcasted shape back to original tensor shape.</p>
<p>This handles gradient reduction for broadcasting operations and matrix operations.
The key insight is that we need to sum over dimensions where the target tensor
was smaller than the result, not rely on the broadcast_shape parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>grad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a></span>) – Gradient array from upstream</p></li>
<li><p><strong>target_shape</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#Ellipsis" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">...</span></code></a>]</span>) – Original tensor shape to reduce to</p></li>
<li><p><strong>broadcast_shape</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#Ellipsis" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">...</span></code></a>]</span>) – Shape that was used in the operation (may be ignored)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Reduced gradient array matching target_shape</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.utils.get_broadcast_shape">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.utils.</span></span><span class="sig-name descname"><span class="pre">get_broadcast_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/utils.html#get_broadcast_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.utils.get_broadcast_shape" title="Link to this definition"></a></dt>
<dd><p>Compute the broadcasted shape of multiple tensor shapes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*shapes</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#Ellipsis" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">...</span></code></a>]</span>) – Variable number of tensor shapes</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#Ellipsis" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">...</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Broadcasted shape</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If shapes cannot be broadcasted</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.utils.validate_tensor_operation">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.utils.</span></span><span class="sig-name descname"><span class="pre">validate_tensor_operation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">operation</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/utils.html#validate_tensor_operation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.utils.validate_tensor_operation" title="Link to this definition"></a></dt>
<dd><p>Validate that two tensors can be used in an operation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – First tensor</p></li>
<li><p><strong>b</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Second tensor</p></li>
<li><p><strong>operation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>) – Name of the operation for error messages</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.13)"><strong>TypeError</strong></a> – If inputs are not tensors</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If tensors are incompatible</p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.utils.ensure_tensor">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.utils.</span></span><span class="sig-name descname"><span class="pre">ensure_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tensor'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/utils.html#ensure_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.utils.ensure_tensor" title="Link to this definition"></a></dt>
<dd><p>Ensure a value is a Tensor, converting if necessary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">any</span></code></span>) – Value to convert</p></li>
<li><p><strong>name</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>) – Name for error messages</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor instance</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.13)"><strong>TypeError</strong></a> – If value cannot be converted to tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.utils.compute_output_shape">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.utils.</span></span><span class="sig-name descname"><span class="pre">compute_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">operation</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/utils.html#compute_output_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.utils.compute_output_shape" title="Link to this definition"></a></dt>
<dd><p>Compute output shape for various tensor operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#Ellipsis" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">...</span></code></a>]</span>) – Input tensor shape</p></li>
<li><p><strong>operation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>) – Operation name</p></li>
<li><p><strong>**kwargs</strong> – Operation-specific parameters</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/constants.html#Ellipsis" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">...</span></code></a>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Output shape</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If operation is not supported or parameters are invalid</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.utils.check_finite_gradients">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.utils.</span></span><span class="sig-name descname"><span class="pre">check_finite_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">operation</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/utils.html#check_finite_gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.utils.check_finite_gradients" title="Link to this definition"></a></dt>
<dd><p>Check if tensor gradients are finite and log warnings if not.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="core.html#neural_arch.core.Tensor" title="neural_arch.core.tensor.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span>) – Tensor to check</p></li>
<li><p><strong>operation</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>) – Operation name for logging</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.utils.apply_gradient_clipping">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.utils.</span></span><span class="sig-name descname"><span class="pre">apply_gradient_clipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/utils.html#apply_gradient_clipping"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.utils.apply_gradient_clipping" title="Link to this definition"></a></dt>
<dd><p>Apply gradient clipping to prevent gradient explosion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>grad</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a></span>) – Gradient array</p></li>
<li><p><strong>max_norm</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a></span>) – Maximum allowed gradient norm</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Clipped gradient array</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="neural_arch.functional.utils.memory_efficient_operation">
<span class="sig-prename descclassname"><span class="pre">neural_arch.functional.utils.</span></span><span class="sig-name descname"><span class="pre">memory_efficient_operation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/neural_arch/functional/utils.html#memory_efficient_operation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#neural_arch.functional.utils.memory_efficient_operation" title="Link to this definition"></a></dt>
<dd><p>Decorator to add memory monitoring to tensor operations.</p>
<p>This is a placeholder for enterprise memory monitoring.
In a production system, this would track memory usage,
detect memory leaks, and provide optimization suggestions.</p>
</dd></dl>

</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Link to this heading"></a></h2>
<section id="basic-operations">
<h3>Basic Operations<a class="headerlink" href="#basic-operations" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">neural_arch.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">neural_arch</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">na</span>

<span class="c1"># Create tensors</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Arithmetic operations</span>
<span class="n">z1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>        <span class="c1"># Element-wise addition</span>
<span class="n">z2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>        <span class="c1"># Element-wise multiplication</span>
<span class="n">z3</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>     <span class="c1"># Matrix multiplication</span>

<span class="c1"># Activation functions</span>
<span class="n">activated</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">activated</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="broadcasting-examples">
<h3>Broadcasting Examples<a class="headerlink" href="#broadcasting-examples" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Broadcasting in arithmetic operations</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Shape: (1, 3)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Shape: (3, 1)</span>

<span class="c1"># Broadcasts to (3, 3)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result shape: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># (3, 3)</span>
</pre></div>
</div>
</section>
<section id="activation-function-usage">
<h3>Activation Function Usage<a class="headerlink" href="#activation-function-usage" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ReLU activation</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">relu_output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [0, 0, 1, 2]</span>

<span class="c1"># Softmax for probability distributions</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>  <span class="c1"># Each row sums to 1</span>

<span class="c1"># Sigmoid for binary classification</span>
<span class="n">binary_logits</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">binary_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">binary_logits</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="loss-function-examples">
<h3>Loss Function Examples<a class="headerlink" href="#loss-function-examples" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cross-entropy loss for classification</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># Class indices</span>
<span class="n">ce_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

<span class="c1"># Mean squared error for regression</span>
<span class="n">predicted_values</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">actual_values</span> <span class="o">=</span> <span class="n">na</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">])</span>
<span class="n">mse_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">predicted_values</span><span class="p">,</span> <span class="n">actual_values</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="performance-notes">
<h2>Performance Notes<a class="headerlink" href="#performance-notes" title="Link to this heading"></a></h2>
<p>The functional operations are implemented with NumPy for optimal performance:</p>
<ul class="simple">
<li><p><strong>Vectorized Operations</strong>: All operations use NumPy’s vectorized implementations</p></li>
<li><p><strong>Broadcasting</strong>: Automatic broadcasting following NumPy conventions</p></li>
<li><p><strong>Memory Efficiency</strong>: Operations minimize memory allocations where possible</p></li>
<li><p><strong>BLAS Integration</strong>: Matrix operations leverage optimized BLAS libraries</p></li>
</ul>
<p>The functional API is designed to be composable and efficient, serving as the foundation for higher-level neural network modules.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="core.html" class="btn btn-neutral float-left" title="Core Module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nn.html" class="btn btn-neutral float-right" title="Neural Network Module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Neural Architecture Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>