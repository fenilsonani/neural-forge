"""Enhanced comprehensive test coverage for backend utils to achieve 95%+ coverage."""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

import pytest
import platform
from unittest.mock import patch, MagicMock
from neural_arch.backends.utils import (
    auto_select_backend,
    get_device_for_backend,
    get_backend_for_device,
    print_available_devices
)
from neural_arch.backends import get_backend, set_backend


class TestBackendUtilsEnhanced:
    """Enhanced comprehensive tests for backend utils targeting 95%+ coverage."""
    
    def setup_method(self):
        """Setup method run before each test."""
        # Store original backend to restore later
        self.original_backend = None
        try:
            self.original_backend = get_backend()
        except:
            pass
    
    def teardown_method(self):
        """Cleanup after each test."""
        # Restore original backend
        if self.original_backend:
            try:
                set_backend(self.original_backend.name)
            except:
                pass
    
    def test_auto_select_backend_prefer_gpu_false(self):
        """Test auto_select_backend when prefer_gpu is False."""
        with patch('neural_arch.backends.utils.set_backend') as mock_set:
            with patch('neural_arch.backends.utils.get_backend') as mock_get:
                mock_backend = MagicMock()
                mock_backend.name = "numpy"
                mock_get.return_value = mock_backend
                
                result = auto_select_backend(prefer_gpu=False)
                
                mock_set.assert_called_with("numpy")
                assert result == mock_backend
    
    def test_auto_select_backend_mps_on_apple_silicon(self):
        """Test auto_select_backend on Apple Silicon (prefers MPS)."""
        with patch('neural_arch.backends.utils.sys.platform', "darwin"):
            with patch('neural_arch.backends.utils.platform.machine', return_value="arm64"):
                with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "mps"]):
                    with patch('neural_arch.backends.utils.set_backend') as mock_set:
                        with patch('neural_arch.backends.utils.get_backend') as mock_get:
                            mock_backend = MagicMock()
                            mock_backend.name = "mps"
                            mock_get.return_value = mock_backend
                            
                            result = auto_select_backend(prefer_gpu=True)
                            
                            mock_set.assert_called_with("mps")
                            assert result == mock_backend
    
    def test_auto_select_backend_mps_unavailable_on_apple_silicon(self):
        """Test auto_select_backend when MPS is listed but not actually available."""
        with patch('neural_arch.backends.utils.sys.platform', "darwin"):
            with patch('neural_arch.backends.utils.platform.machine', return_value="arm64"):
                with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "mps"]):
                    with patch('neural_arch.backends.utils.set_backend') as mock_set:
                        with patch('neural_arch.backends.utils.get_backend') as mock_get:
                            # First call to set_backend raises error, second succeeds
                            def side_effect(backend_name):
                                if backend_name == "mps":
                                    raise ValueError("MPS not available")
                                # For numpy backend, just pass
                                pass
                            
                            mock_set.side_effect = side_effect
                            
                            mock_backend = MagicMock()
                            mock_backend.name = "numpy"
                            mock_get.return_value = mock_backend
                            
                            result = auto_select_backend(prefer_gpu=True)
                            
                            # Should try MPS first, then fallback to numpy
                            assert mock_set.call_count == 2
                            mock_set.assert_any_call("mps")
                            mock_set.assert_any_call("numpy")
                            assert result == mock_backend
    
    def test_auto_select_backend_mps_import_error_on_apple_silicon(self):
        """Test auto_select_backend when MPS raises ImportError."""
        with patch('neural_arch.backends.utils.sys.platform', "darwin"):
            with patch('neural_arch.backends.utils.platform.machine', return_value="arm64"):
                with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "mps"]):
                    with patch('neural_arch.backends.utils.set_backend') as mock_set:
                        with patch('neural_arch.backends.utils.get_backend') as mock_get:
                            # First call to set_backend raises ImportError, second succeeds
                            def side_effect(backend_name):
                                if backend_name == "mps":
                                    raise ImportError("MLX not installed")
                                # For numpy backend, just pass
                                pass
                            
                            mock_set.side_effect = side_effect
                            
                            mock_backend = MagicMock()
                            mock_backend.name = "numpy"
                            mock_get.return_value = mock_backend
                            
                            result = auto_select_backend(prefer_gpu=True)
                            
                            # Should try MPS first, then fallback to numpy
                            assert mock_set.call_count == 2
                            mock_set.assert_any_call("mps")
                            mock_set.assert_any_call("numpy")
                            assert result == mock_backend
    
    def test_auto_select_backend_cuda_available(self):
        """Test auto_select_backend when CUDA is available."""
        with patch('neural_arch.backends.utils.sys.platform', "linux"):
            with patch('neural_arch.backends.utils.platform.machine', return_value="x86_64"):
                with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "cuda"]):
                    with patch('neural_arch.backends.utils.set_backend') as mock_set:
                        with patch('neural_arch.backends.utils.get_backend') as mock_get:
                            mock_backend = MagicMock()
                            mock_backend.name = "cuda"
                            mock_get.return_value = mock_backend
                            
                            result = auto_select_backend(prefer_gpu=True)
                            
                            mock_set.assert_called_with("cuda")
                            assert result == mock_backend
    
    def test_auto_select_backend_cuda_unavailable(self):
        """Test auto_select_backend when CUDA is listed but not actually available."""
        with patch('neural_arch.backends.utils.sys.platform', "linux"):
            with patch('neural_arch.backends.utils.platform.machine', return_value="x86_64"):
                with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "cuda"]):
                    with patch('neural_arch.backends.utils.set_backend') as mock_set:
                        with patch('neural_arch.backends.utils.get_backend') as mock_get:
                            # First call to set_backend raises error, second succeeds
                            def side_effect(backend_name):
                                if backend_name == "cuda":
                                    raise ValueError("CUDA not available")
                                # For numpy backend, just pass
                                pass
                            
                            mock_set.side_effect = side_effect
                            
                            mock_backend = MagicMock()
                            mock_backend.name = "numpy"
                            mock_get.return_value = mock_backend
                            
                            result = auto_select_backend(prefer_gpu=True)
                            
                            # Should try CUDA first, then fallback to numpy
                            assert mock_set.call_count == 2
                            mock_set.assert_any_call("cuda")
                            mock_set.assert_any_call("numpy")
                            assert result == mock_backend
    
    def test_auto_select_backend_cuda_import_error(self):
        """Test auto_select_backend when CUDA raises ImportError."""
        with patch('neural_arch.backends.utils.sys.platform', "linux"):
            with patch('neural_arch.backends.utils.platform.machine', return_value="x86_64"):
                with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "cuda"]):
                    with patch('neural_arch.backends.utils.set_backend') as mock_set:
                        with patch('neural_arch.backends.utils.get_backend') as mock_get:
                            # First call to set_backend raises ImportError, second succeeds
                            def side_effect(backend_name):
                                if backend_name == "cuda":
                                    raise ImportError("CuPy not installed")
                                # For numpy backend, just pass
                                pass
                            
                            mock_set.side_effect = side_effect
                            
                            mock_backend = MagicMock()
                            mock_backend.name = "numpy"
                            mock_get.return_value = mock_backend
                            
                            result = auto_select_backend(prefer_gpu=True)
                            
                            # Should try CUDA first, then fallback to numpy
                            assert mock_set.call_count == 2
                            mock_set.assert_any_call("cuda")
                            mock_set.assert_any_call("numpy")
                            assert result == mock_backend
    
    def test_auto_select_backend_no_gpu_available(self):
        """Test auto_select_backend when no GPU backends are available."""
        with patch('neural_arch.backends.utils.sys.platform', "linux"):
            with patch('neural_arch.backends.utils.platform.machine', return_value="x86_64"):
                with patch('neural_arch.backends.utils.available_backends', return_value=["numpy"]):
                    with patch('neural_arch.backends.utils.set_backend') as mock_set:
                        with patch('neural_arch.backends.utils.get_backend') as mock_get:
                            mock_backend = MagicMock()
                            mock_backend.name = "numpy"
                            mock_get.return_value = mock_backend
                            
                            result = auto_select_backend(prefer_gpu=True)
                            
                            # Should fallback to numpy
                            mock_set.assert_called_with("numpy")
                            assert result == mock_backend
    
    def test_get_device_for_backend_with_backend_name(self):
        """Test get_device_for_backend with explicit backend name."""
        assert get_device_for_backend("numpy") == "cpu"
        assert get_device_for_backend("cuda") == "cuda"
        assert get_device_for_backend("mps") == "mps"
        assert get_device_for_backend("unknown") == "cpu"
    
    def test_get_device_for_backend_with_current_backend(self):
        """Test get_device_for_backend with current backend."""
        with patch('neural_arch.backends.utils.get_backend') as mock_get:
            mock_backend = MagicMock()
            mock_backend.name = "cuda"
            mock_get.return_value = mock_backend
            
            result = get_device_for_backend(None)
            assert result == "cuda"
            mock_get.assert_called_once()
    
    def test_get_backend_for_device(self):
        """Test get_backend_for_device with various device strings."""
        assert get_backend_for_device("cpu") == "numpy"
        assert get_backend_for_device("CPU") == "numpy"  # Case insensitive
        assert get_backend_for_device("cuda") == "cuda"
        assert get_backend_for_device("CUDA") == "cuda"  # Case insensitive
        assert get_backend_for_device("cuda:0") == "cuda"  # With device index
        assert get_backend_for_device("cuda:1") == "cuda"  # With device index
        assert get_backend_for_device("mps") == "mps"
        assert get_backend_for_device("MPS") == "mps"  # Case insensitive
        assert get_backend_for_device("mps:0") == "mps"  # With device index
        assert get_backend_for_device("unknown") == "numpy"  # Default fallback
        assert get_backend_for_device("gpu") == "numpy"  # Generic GPU falls back
    
    def test_print_available_devices_comprehensive(self):
        """Test print_available_devices with comprehensive device info."""
        mock_caps = {
            'cpu': {
                'architecture': 'x86_64',
                'available': True
            },
            'cuda': {
                'available': True,
                'devices': [
                    {
                        'index': 0,
                        'name': 'NVIDIA GeForce RTX 3080',
                        'memory': 10737418240,  # 10 GB
                        'compute_capability': '8.6'
                    },
                    {
                        'index': 1,
                        'name': 'NVIDIA GeForce RTX 3090',
                        'memory': 25769803776,  # 24 GB
                        'compute_capability': '8.6'
                    }
                ]
            },
            'mps': {
                'available': True,
                'unified_memory': True
            }
        }
        
        with patch('neural_arch.core.device.get_device_capabilities', return_value=mock_caps):
            with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "cuda", "mps"]):
                with patch('builtins.print') as mock_print:
                    print_available_devices()
                    
                    # Check that key information was printed
                    print_calls = [call[0][0] for call in mock_print.call_args_list]
                    print_output = "\n".join(print_calls)
                    
                    # Verify core sections are present
                    assert "Available Compute Devices:" in print_output
                    assert "CPU:" in print_output
                    assert "Architecture: x86_64" in print_output
                    assert "CUDA:" in print_output
                    assert "Available: True" in print_output
                    assert "NVIDIA GeForce RTX 3080" in print_output
                    assert "NVIDIA GeForce RTX 3090" in print_output
                    assert "MPS" in print_output
                    assert "Available Backends:" in print_output
    
    def test_print_available_devices_cuda_unavailable(self):
        """Test print_available_devices when CUDA is unavailable."""
        mock_caps = {
            'cpu': {
                'architecture': 'arm64',
                'available': True
            },
            'cuda': {
                'available': False
            },
            'mps': {
                'available': True,
                'unified_memory': True
            }
        }
        
        with patch('neural_arch.core.device.get_device_capabilities', return_value=mock_caps):
            with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "mps"]):
                with patch('builtins.print') as mock_print:
                    print_available_devices()
                    
                    # Check that CUDA unavailable message is printed
                    print_calls = [call[0][0] for call in mock_print.call_args_list]
                    assert any("CUDA: Not available" in call for call in print_calls)
    
    def test_print_available_devices_mps_unavailable(self):
        """Test print_available_devices when MPS is unavailable."""
        mock_caps = {
            'cpu': {
                'architecture': 'x86_64',
                'available': True
            },
            'cuda': {
                'available': True,
                'devices': [
                    {
                        'index': 0,
                        'name': 'NVIDIA RTX 4090',
                        'memory': 25769803776,
                        'compute_capability': '8.9'
                    }
                ]
            },
            'mps': {
                'available': False
            }
        }
        
        with patch('neural_arch.core.device.get_device_capabilities', return_value=mock_caps):
            with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "cuda"]):
                with patch('builtins.print') as mock_print:
                    print_available_devices()
                    
                    # Check that MPS unavailable message is printed
                    print_calls = [call[0][0] for call in mock_print.call_args_list]
                    assert any("MPS: Not available" in call for call in print_calls)
    
    def test_print_available_devices_no_gpu(self):
        """Test print_available_devices when no GPU is available."""
        mock_caps = {
            'cpu': {
                'architecture': 'x86_64',
                'available': True
            },
            'cuda': {
                'available': False
            },
            'mps': {
                'available': False
            }
        }
        
        with patch('neural_arch.core.device.get_device_capabilities', return_value=mock_caps):
            with patch('neural_arch.backends.utils.available_backends', return_value=["numpy"]):
                with patch('builtins.print') as mock_print:
                    print_available_devices()
                    
                    # Check that both GPU backends show as unavailable
                    print_calls = [call[0][0] for call in mock_print.call_args_list]
                    assert any("CUDA: Not available" in call for call in print_calls)
                    assert any("MPS: Not available" in call for call in print_calls)
                    assert any("Available Backends: numpy" in call for call in print_calls)
    
    def test_edge_cases_and_error_conditions(self):
        """Test edge cases and error conditions."""
        # Test get_device_for_backend with None when no current backend
        with patch('neural_arch.backends.utils.get_backend', side_effect=Exception("No backend")):
            # Should handle exception gracefully and return default
            try:
                result = get_device_for_backend(None)
                # If it doesn't raise an exception, that's good
            except:
                # If it does raise, that's also acceptable behavior
                pass
    
    def test_platform_specific_behavior(self):
        """Test platform-specific behavior in auto_select_backend."""
        # Test on non-Darwin platform (should prefer CUDA over MPS)
        with patch('neural_arch.backends.utils.sys.platform', "linux"):
            with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "cuda", "mps"]):
                with patch('neural_arch.backends.utils.set_backend') as mock_set:
                    with patch('neural_arch.backends.utils.get_backend') as mock_get:
                        mock_backend = MagicMock()
                        mock_backend.name = "cuda"
                        mock_get.return_value = mock_backend
                        
                        result = auto_select_backend(prefer_gpu=True)
                        
                        # Should prefer CUDA over MPS on non-Darwin platforms
                        mock_set.assert_called_with("cuda")
                        assert result == mock_backend
        
        # Test on Darwin platform with Intel architecture (should prefer CUDA over MPS)
        with patch('neural_arch.backends.utils.sys.platform', "darwin"):
            with patch('neural_arch.backends.utils.platform.machine', return_value="x86_64"):
                with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "cuda", "mps"]):
                    with patch('neural_arch.backends.utils.set_backend') as mock_set:
                        with patch('neural_arch.backends.utils.get_backend') as mock_get:
                            mock_backend = MagicMock()
                            mock_backend.name = "cuda"
                            mock_get.return_value = mock_backend
                            
                            result = auto_select_backend(prefer_gpu=True)
                            
                            # Should prefer CUDA over MPS on Intel Macs
                            mock_set.assert_called_with("cuda")
                            assert result == mock_backend
    
    def test_device_string_variations(self):
        """Test various device string formats."""
        # Test various CUDA device strings
        assert get_backend_for_device("cuda:0") == "cuda"
        assert get_backend_for_device("cuda:10") == "cuda"
        assert get_backend_for_device("cuda:999") == "cuda"
        
        # Test various MPS device strings  
        assert get_backend_for_device("mps:0") == "mps"
        assert get_backend_for_device("mps:1") == "mps"
        
        # Test case variations
        assert get_backend_for_device("Cpu") == "numpy"
        assert get_backend_for_device("CUDA:0") == "cuda"
        assert get_backend_for_device("Mps") == "mps"
        
        # Test edge cases
        assert get_backend_for_device("") == "numpy"  # Empty string
        assert get_backend_for_device("  ") == "numpy"  # Whitespace
        assert get_backend_for_device("cpu:") == "numpy"  # Trailing colon
        assert get_backend_for_device("cuda:") == "cuda"  # Trailing colon
    
    def test_import_dependencies(self):
        """Test that all required imports work correctly."""
        # This test ensures that the import dependencies are correctly handled
        from neural_arch.backends.utils import (
            auto_select_backend,
            get_device_for_backend, 
            get_backend_for_device,
            print_available_devices
        )
        
        # All functions should be callable
        assert callable(auto_select_backend)
        assert callable(get_device_for_backend)
        assert callable(get_backend_for_device)
        assert callable(print_available_devices)
    
    def test_memory_formatting_in_print_devices(self):
        """Test memory formatting in print_available_devices."""
        mock_caps = {
            'cpu': {'architecture': 'x86_64', 'available': True},
            'cuda': {
                'available': True,
                'devices': [
                    {
                        'index': 0,
                        'name': 'Test GPU',
                        'memory': 1073741824,  # 1 GB exactly
                        'compute_capability': '8.0'
                    },
                    {
                        'index': 1, 
                        'name': 'Test GPU 2',
                        'memory': 8589934592,  # 8 GB exactly
                        'compute_capability': '8.6'
                    }
                ]
            },
            'mps': {'available': False}
        }
        
        with patch('neural_arch.core.device.get_device_capabilities', return_value=mock_caps):
            with patch('neural_arch.backends.utils.available_backends', return_value=["numpy", "cuda"]):
                with patch('builtins.print') as mock_print:
                    print_available_devices()
                    
                    # Check memory formatting - just verify some memory info is present
                    print_calls = [call[0][0] for call in mock_print.call_args_list]
                    print_output = "\n".join(print_calls)
                    assert "GB" in print_output  # Memory info should contain GB